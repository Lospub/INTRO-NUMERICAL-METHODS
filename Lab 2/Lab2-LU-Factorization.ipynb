{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6CaRdIf_xd6i"
   },
   "source": [
    "<h2>Lab 2: LU Factorization</h2>\n",
    "<b>Demo Date: </b> Sept. 22 <br>\n",
    "<b>Due Date: </b> Sept. 25\n",
    "\n",
    "In this lab you will implement two versions of the LU Factorization algorithm: the one presented in the pseudocode of the textbook and another that uses Numpy operations with matrices. We will then compare the performance of the two implementations on artificial problems. Here we will assume that the linear system has a single solution and that pivoting isn't needed (we will study pivoting in our Tuesday lecture).\n",
    "\n",
    "In class we discussed how the matrix $A$ of a linear system $Ax = b$ can be decomposed into a lower triangular matrix $L$ and an upper triangular matrix $U$. i.e., $A = LU$. The decomposition allows us to write the original system as $LUx = b$. Then, we make $y = Ux$ and solve the system $Ly = b$ with an algorithm called forward-substitution. The solution $y$ is then be used to discover the solution to the original problem, by making $Ux = y$ and solving this system with the back-substitution algorithm. \n",
    "\n",
    "In class we studied the back-substitution algorithm, which is very similar to the forward-substitution algorithm. Back-substitution solves systems whose matrix A is an upper triangular matrix, while forward-substitution solves systems whose matrix A is a lower triangular matrix. \n",
    "\n",
    "Before moving forward, please take a look at the pseudocode of the forward and back-substitution algorithms in the textbook (see Algorithm 2.1 on page 64 and Algorithm 2.2 on page 65). If you understand the forward and back-substitution algorithms, then please go ahead and study the pseudocode of the LU-factorization (see Algorithm 2.3 on page 68 of the textbook). \n",
    "\n",
    "Let's now implement these three algorithms to solve the system used as example in class. \n",
    "\n",
    "\\begin{align*}\n",
    "Ax = \\begin{bmatrix}\n",
    "1 & 2 & 2 \\\\\n",
    "4 & 4 & 2 \\\\\n",
    "4 & 6 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "3 \\\\\n",
    "6 \\\\\n",
    "10 \\\\\n",
    "\\end{bmatrix} = b\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vISWONpHxd6j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import scipy.linalg\n",
    "\n",
    "A = np.array([[1, 2, 2], [4, 4, 2], [4, 6, 4]])\n",
    "b = np.array([3, 6, 10]).reshape(3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GctFvb87xd6n"
   },
   "source": [
    "Finish the implementation of the algorithms below. The implementation of these algorithms should follow the pseudocode of the textbook. \n",
    "\n",
    "The output should be $x = [-1, 3, -1]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OT8OfqWxd6n",
    "outputId": "d1140cb7-5eb4-44f2-c492-be7b792d6b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [-1.  3. -1.]\n"
     ]
    }
   ],
   "source": [
    "def forward_substituion(L, b):\n",
    "    x = np.zeros((b.shape[0]))\n",
    "    for j in range(0, L.shape[1]):\n",
    "        # singular matrix\n",
    "        if L[j][j] == 0:\n",
    "            break \n",
    "        x[j] = b[j]/ L[j][j]\n",
    "    \n",
    "        for i in range(j, L.shape[0]):\n",
    "            b[i] = b[i] - L[i][j] * x[j]\n",
    "    return x\n",
    "\n",
    "def back_substituion(U, b):\n",
    "    x = np.zeros((b.shape[0]))\n",
    "    for j in range(U.shape[1]-1,-1,-1):\n",
    "        # singular matrix\n",
    "        if U[j][j] == 0:\n",
    "            break \n",
    "        x[j] = b[j]/ U[j][j]\n",
    "    \n",
    "        for i in range(0,j):\n",
    "            b[i] = b[i] - U[i][j] * x[j]\n",
    "    return x.transpose()\n",
    "\n",
    "def lu_factor_v1(A):\n",
    "    L = np.eye(A.shape[0])\n",
    "    \n",
    "    for k in range(A.shape[1]):\n",
    "        if A[k][k] == 0:\n",
    "            break\n",
    "        for i in range(k+1,A.shape[0]):\n",
    "            L[i][k] = A[i][k]/A[k][k]\n",
    "            #A[i][k] = 0\n",
    "        for j in range(k+1,A.shape[0]):\n",
    "            for i in range(k+1,A.shape[0]):\n",
    "                A[i][j] = A[i][j] - L[i][k]*A[k][j]\n",
    "                \n",
    "    #print(L)\n",
    "    #print(A)\n",
    "    return L, A\n",
    "\n",
    "n = len(b)\n",
    "A1 = copy.deepcopy(A)\n",
    "b1 = copy.deepcopy(b)\n",
    "\n",
    "L, U = lu_factor_v1(A1)\n",
    "#print(\"L:\\n\", L)\n",
    "#print(\"U:\\n\", U)\n",
    "y = forward_substituion(L, b1)\n",
    "#print(y)\n",
    "x = back_substituion(U, y)\n",
    "\n",
    "print('x: ', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wbjg-hszxd6q"
   },
   "source": [
    "Next, we will write a vectorized implementation of the LU factorization. For that you will modify your previous implementation. The only for-loop you will keep in the vectorized implementation is the outer loop of the non-vectorized implementation, the one that iterates over the $k-1$ columns of $A$. You should rely on numpy functions to rewrite the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzfeTuy0xd6r",
    "outputId": "eb959e24-c87e-4b17-ae52-480137f65bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [-1.  3. -1.]\n"
     ]
    }
   ],
   "source": [
    "def lu_factor_v2(A):\n",
    "    L = np.eye(A.shape[0])\n",
    "    U = A.copy()\n",
    "    for k in range(U.shape[1]):\n",
    "        if U[k][k] == 0:\n",
    "            break\n",
    "       # for i in range(k+1,A.shape[0]):\n",
    "       #     M[i][k] = A[i][k]/A[k][k]\n",
    "       #     A[i][k] = 0\n",
    "       # for j in range(k+1,A.shape[1]):\n",
    "       #     for i in range(k+1,A.shape[1]):\n",
    "       #         A[i][j] = A[i][j] - M[i][k]*A[k][j]\n",
    "        \n",
    "        temp = U[k+1:,k]/U[k,k]\n",
    "        L[k+1:,k] = temp\n",
    "        # adding the dimention to increase the shape of the temp, to make temp*U[k] caculable\n",
    "        # here is the citation for adding dimentionï¼š\n",
    "        # https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html\n",
    "        temp = np.expand_dims(temp, axis=1)\n",
    "        U[k+1:] = U[k+1:] - np.multiply(temp,U[k])\n",
    "        # print(U[k])\n",
    "        # print(U[k+1:, k]/U[k, k] * U[k])\n",
    "        # print(U[k+1:, k]/U[k, k])\n",
    "    #print(U)\n",
    "    #print(L)    \n",
    "        \n",
    "    return L, U\n",
    "    \n",
    "L, U = lu_factor_v2(copy.deepcopy(A))\n",
    "y = forward_substituion(L, copy.deepcopy(b))\n",
    "x = back_substituion(U, y)\n",
    "print('x: ', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAC5DqIyxd6u"
   },
   "source": [
    "In the following snippet we will compare the running time of the vectorized and non-vectorized implementation by performing the LU-factorization on larger $200 \\times 200$ matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrlKURNqxd6u",
    "outputId": "d34fa351-d68b-473e-ae14-d01afba7c97f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Vectorized: 5.2373 seconds\n",
      "Vectorized: 0.0225 seconds\n"
     ]
    }
   ],
   "source": [
    "running_time_vectorized = []\n",
    "running_time_non_vectorized = []\n",
    "\n",
    "for _ in range(10):\n",
    "    test_A = np.tril(np.random.rand(200, 200))\n",
    "    \n",
    "    A = copy.deepcopy(test_A)\n",
    "    start = time.time()\n",
    "    L, U = lu_factor_v1(A)\n",
    "    end = time.time()\n",
    "    running_time_non_vectorized.append(end - start)\n",
    "    \n",
    "    A = copy.deepcopy(test_A)\n",
    "    start = time.time()\n",
    "    L, U = lu_factor_v2(A)\n",
    "    end = time.time()\n",
    "    running_time_vectorized.append(end - start)\n",
    "\n",
    "print('Non-Vectorized: %.4f seconds' % np.average(running_time_non_vectorized))\n",
    "print('Vectorized: %.4f seconds' % np.average(running_time_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab2-LU-Factorization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
